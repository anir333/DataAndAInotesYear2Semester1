{"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"id":"o5IXxxDJpF4t","jupyter":{"outputs_hidden":false}},"source":["## Exercises Hyperparameter tuning and model validation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T15:53:17.185611Z","start_time":"2024-10-13T15:53:17.153174Z"},"id":"WlVApf6xpF4u"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"24i-D07hpF4v","jupyter":{"outputs_hidden":false}},"source":["![Predictions on training set](https://drive.google.com/file/d/1-WkGT0GDrel7-QWpotn7xNicpg0wOD1U/view?usp=sharing)\n","\n","1. Above you see three predictions on training sets. We have only one feature x and a target variable Y.\n","What can you say about the data in situation A, B and C?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T15:53:17.196605Z","start_time":"2024-10-13T15:53:17.164136Z"},"id":"cQWs7v-ApF4w"},"outputs":[],"source":["#SOLUTION_START\n","\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"PluKmu2_pF4x","jupyter":{"outputs_hidden":false}},"source":["2. My data is underfitted. What are 3 possible ways to solve this?"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T15:53:18.903032Z","start_time":"2024-10-13T15:53:18.867369Z"},"id":"l1oTTO8upF4x"},"outputs":[],"source":["#SOLUTION_START\n","\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"iHsnZI0tpF6q","jupyter":{"outputs_hidden":false}},"source":["3. My data is overfitted. Provide 3 possible ways to solve this?"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T15:53:21.063780Z","start_time":"2024-10-13T15:53:20.859881Z"},"id":"0f6m_4LfpF6q"},"outputs":[],"source":["#SOLUTION_START\n","\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"xJqqzvwhpF6r","jupyter":{"outputs_hidden":false}},"source":[" We load the data again from the Concrete Compressive Strength Dataset Regression Notebook\n"," Import the necessary libraries (Import pandas, numpy, matplotlib, seaborn, and sklearn libraries)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:23.414542Z","start_time":"2024-10-13T18:51:23.250821Z"},"id":"SLQ9qVqZpF6s"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.metrics import mean_squared_error, r2_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:23.634903Z","start_time":"2024-10-13T18:51:23.551264Z"},"id":"RtAVIAsLpF6s"},"outputs":[],"source":["\n","df = pd.read_csv('data/concrete_data.csv')\n","# Display the first few rows to understand the structure of the dataset\n","df.head()\n"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"Eb6-96GRpF6t","jupyter":{"outputs_hidden":false}},"source":["4. Construct a pipeline PolynomialRegression. First you create the variables with PolynomialFeatures and you feed this data to the linear regression."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:24.891126Z","start_time":"2024-10-13T18:51:24.850098Z"},"id":"NCo39aidpF6u"},"outputs":[],"source":["#SOLUTION_START\n","\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"uUUI7UxppF6u","jupyter":{"outputs_hidden":false}},"source":["5. From the concrete dataset you predict the strength csMPa by the cement feature.First select the cement feature and transform the series into a numpy array. To plot the regression you need to know the min and max vaules of cement."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:26.267506Z","start_time":"2024-10-13T18:51:26.194697Z"},"id":"Jq3pvajppF6u"},"outputs":[],"source":["#SOLUTION_START\n","\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"oxCb5g23pF6v","jupyter":{"outputs_hidden":false}},"source":["6. Plot the data for different polyniomial models ( degrees are different). Is the data underfitted or overfitted?"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:28.584325Z","start_time":"2024-10-13T18:51:27.833295Z"},"id":"ovBR-A3EpF6v"},"outputs":[],"source":["#SOLUTION_START\n","\n","#we see all models perform poorly on the training set --> underfitting\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"jQE9VvUspF6w","jupyter":{"outputs_hidden":false}},"source":["7. Plot the result on the training set and the validation set. Use a cross-validation value of 7. Do the graph confirm what you think about (underfitting/overfitting)? Is it useful to use a more complex model?"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:29.346076Z","start_time":"2024-10-13T18:51:29.332652Z"},"id":"PQWMDaAVpF6w"},"outputs":[],"source":["import sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:30.740793Z","start_time":"2024-10-13T18:51:30.173887Z"},"id":"Of-SWsvNpF6w"},"outputs":[],"source":["#SOLUTION_START\n","\n","\n","\n","# Define the pipeline for Polynomial Regression\n","\n","\n","# Define the range of degrees for the polynomial features\n","\n","# Get validation curve scores\n","\n","\n","# Plot the learning curves\n","\n","# no the results are overall poor even for the training set. We see that the validation set have the best results for degree 1.\n","# But the model is not useful\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"uL-cqNtcpF6x","jupyter":{"outputs_hidden":false}},"source":["8. To improve the results we include more features: include also water and age in X"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:31.660752Z","start_time":"2024-10-13T18:51:31.651311Z"},"id":"GqJwTT2VpF6x"},"outputs":[],"source":["#SOLUTION_START\n","\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"ztyAj1NTpF6y","jupyter":{"outputs_hidden":false}},"source":["9. Plot the validation_curve for these features, optionally you even can add a standardscaler to your pipeline. Be aware that the cross validation score uses the negative mean square error (see documentation). Investigate for degrees 1 up to 10. Use the median value or the mean for the training scores and the validation scores. You see a sligth difference."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:37.246963Z","start_time":"2024-10-13T18:51:32.923964Z"},"id":"VHyvGpzmpF6y"},"outputs":[],"source":["#SOLUTION_START\n","\n","\n","\n","\n","# Create a pipeline that includes polynomial features and linear regression\n","\n","# Initialize a PolynomialRegression pipeline for a specific degree (start with 2 for demonstration)\n","\n","\n","# Perform cross-validation to evaluate the model\n","\n","# Use cross-validation with 5 folds\n","\n","# Display cross-validation results\n","\n","\n","# Validation curve to check for overfitting/underfitting at different degrees\n","\n","\n","# Plot the validation curve for median\n","\n","\n","# Plot the validation curve for median\n","\n","#SOLUTION_END\n","#we see that degree 3 (2(median) or 4(mean)) are the best choice in this case"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"BEdUxRuNpF6z","jupyter":{"outputs_hidden":false}},"source":["10. Let's use gridsearch to find the optimum degree"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:37.796285Z","start_time":"2024-10-13T18:51:37.257847Z"},"id":"KdHdsszdpF6z"},"outputs":[],"source":["#SOLUTION_START\n","\n","\n","# Select features (cement, water, age) and target (csMPa)\n","\n","\n","# Create a pipeline that includes scaling, polynomial features, and linear regression\n","\n","\n","# Define the grid of parameters to search\n","\n","# Setup the GridSearchCV\n","\n","# Fit the model\n","\n","# Get the best degree and corresponding score\n","\n","\n","# Optional: Visualize the results\n","\n","#SOLUTION_END"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"n0xOwqiypF6z","jupyter":{"outputs_hidden":false}},"source":["11. Extend the model with the same gridsearch but now for a ridge regression and try different ridge factors 1 0.5 and 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2024-10-13T18:51:41.252917Z","start_time":"2024-10-13T18:51:40.140941Z"},"id":"LqZgb5HrpF6z"},"outputs":[],"source":["#SOLUTION_START\n","\n","\n","\n","# Select features (cement, water, age) and target (csMPa)\n","\n","\n","# Create a pipeline that includes scaling, polynomial features, and Ridge regression\n","\n","\n","# Define the grid of parameters to search\n","\n","\n","# Setup the GridSearchCV\n","\n","# Fit the model\n","\n","# Get the best parameters and corresponding score\n","\n","\n","\n","# Optional: Visualize the results\n","\n","#SOLUTION_END"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZoYU2kWipF93"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
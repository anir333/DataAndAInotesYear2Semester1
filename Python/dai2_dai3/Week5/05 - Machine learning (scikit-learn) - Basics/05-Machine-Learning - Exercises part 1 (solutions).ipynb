{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EXERCISES MACHINE LEARNING"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## scikit-learn machine learning pipeline with validation\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(concrete compressive strength dataset)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task 1 : Import libraries"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the necessary libraries (pandas, Numpy, Matplotlib, Seaborn and scikit-learn libraries)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SOLUTION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 2 : Set Seaborn style",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Choose a seaborn style for plots."
  },
  {
   "cell_type": "code",
   "source": [
    "# SOLUTION\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 3 : Load the data",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the 'Concrete_Data.csv' from the data directory and display the first rows."
  },
  {
   "cell_type": "code",
   "source": [
    "# SOLUTION\n",
    "df = pd.read_csv('../datasets/Concrete_Data.csv')\n",
    "# Display the first few rows to understand the structure of the dataset\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 4 : Key statistics and missing values",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Understand the dataset by displaying key statistics and check for missing values"
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION\n",
    "# Key statistics\n",
    "display(df.describe())\n",
    "# Count the number of missing values per column\n",
    "print(df.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 5 : Heatmap with correlations",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot a heatmap of the correlation matrix to understand the relationships between the target variable 'csMPa' and all other variables (predictors)."
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION\n",
    "# plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 6 : Simple linear regression",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Perform a simple linear regression with 'csMPa' as target and one feature.\n",
    "\n",
    "What feature seems to be the best candidate for the job?\n",
    "\n",
    "Use a standard test setup (training set and test set) and make the predictions \n",
    "for the observations in the test set."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION\n",
    "\n",
    "# Select the feature (X) and the target variable (y)\n",
    "# 'cement' has the highest correlation with 'csMPa' and hence is the best \n",
    "# candidate.\n",
    "X = df[['cement']] # Results in a dataframe\n",
    "y = df['csMPa']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a linear regression model\n",
    "lin_reg_one = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lin_reg_one.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred_one = lin_reg_one.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 7 : Validation",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculate and display the R-squared and Mean Squared Error (MSE) for the simple linear regression."
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION\n",
    "print(f'R-squared (Simple Linear Regression): {r2_score(y_test, y_pred_one):.3f}')\n",
    "print(f'Mean Squared Error (Simple Linear Regression): {mean_squared_error(y_test, y_pred_one):.3f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 8 : Regression line",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot the regression line along with the test data points and print the intercept and coefficients."
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual values')\n",
    "plt.plot(X_test, y_pred_one, color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('Cement')\n",
    "plt.ylabel('Compressive Strength (MPa)')\n",
    "plt.legend()\n",
    "plt.title('Simple Linear Regression: Cement vs Strength')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION\n",
    "print(f'Intercept    : {lin_reg_one.intercept_:.3f}')\n",
    "print(f'Coefficients : {lin_reg_one.coef_}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Task 9 : Linear regression with more predictors",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we see the single feature explains the compressive strength not to well. We continue our search for a better model:\n",
    "include more than one variable in our regression model. What other 2 features are potential good candidates?\n",
    "Make predictions for the test set and calculate the Mean Squared Error and R-squared. Print the coefficients and the intercept."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#SOLUTION\n",
    "\n",
    "# Let's include 'Cement', 'Water', and 'Age' as features based on their correlation with the target variable.\n",
    "\n",
    "# Select multiple features (X) and the target variable (y)\n",
    "X = df[['cement', 'water', 'age']]\n",
    "y = df['csMPa']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "lin_regML = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lin_regML.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_predML = lin_regML.predict(X_test)\n",
    "\n",
    "print(f'R-squared          : {r2_score(y_test, y_predML):.3f}')\n",
    "print(f'Mean Squared Error : {mean_squared_error(y_test, y_predML):.3f}')\n",
    "print(f'Intercept          : {lin_regML.intercept_:.3f}')\n",
    "print(f'Coefficients       : {lin_regML.coef_}')\n",
    "#SOLUTION_END"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## scikit-learn machine learning pipeline with model selection and hyperparameter tuning using cross-validation\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. PREDICT PENGUIN SPECIES WITH HYPERPARAMETER TUNING USING CROSS-VALIDATION"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We want to build a model to predict the penguin species based on some penguin characteristics we can observe. We have a labeled dataset <strong>'penguin'</strong> that is part of the Seaborn built-in datasets. We want to use a decision tree and want to experiment with following hyperparameters to find the best solution: maximum tree depth ranging from 3 tot 10, and split criterion equal to 'gini' or 'entropy'. Derive the best model, using a decision tree with the given set of hyperparameter values, using 3-fold cross validation with recall as validation measure for the hyperparameter tuning. Use <strong>species</strong> as the target variable and all other variables except <strong>island</strong> and <strong>sex</strong> as predictors."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DATA PREPARATION\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "import seaborn as sns \n",
    "df = sns.load_dataset('penguins')\n",
    "y = df['species']              # Target feature to predict\n",
    "X = df.copy().drop(['species','island', 'sex'], axis=1) # Predictors\n",
    "\n",
    "print(type(df), df.shape)\n",
    "print(type(X), X.shape)\n",
    "print(type(y), y.shape)\n",
    "\n",
    "display(X.head(5))\n",
    "display(y.head(5))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Explore data\n",
    "display(X.sample(10, random_state=0))\n",
    "display(y.sample(10, random_state=0))\n",
    "# Mind that the indexes of the sample of y might be different of the indexes\n",
    "# of the sample of X because of the random selection.\n",
    "# When using random_state with the same state, you should get the same \n",
    "# indexes.\n",
    "display(X.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SPLIT LABELED DATA INTO TRAIN/VALIDATE - TEST SAMPLE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data randomly into 80% training set and 20% test set\n",
    "X_tr, X_tst, y_tr, y_tst = train_test_split(X, y, random_state=0, train_size=0.8)\n",
    "# (use random_state to be sure that every time the same random sample is drawn)\n",
    "\n",
    "print(type(X_tr), X_tr.shape)\n",
    "print(type(X_tst), X_tst.shape)\n",
    "print(type(y_tr), y_tr.shape)\n",
    "print(type(y_tst), y_tst.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# MODEL SELECTION AND HYPERPARAMETER TUNING (REPEAT THIS STEP FOR MULTIPLE MODELING TECHNIQUES)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define parameter grid (model specific)\n",
    "grid_param = {'criterion' : ['gini', 'entropy'],\n",
    "              'max_depth' : list(range(3,11))}\n",
    "display(grid_param)\n",
    "\n",
    "# Setup grid search with N-fold cross validation (e.g. 5-fold)\n",
    "grid_search = GridSearchCV(model, grid_param, cv=3)\n",
    "\n",
    "# Execute full grid search\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "# Display best hyperparameter values and matching validation score\n",
    "print(f'Best parameters : {grid_search.best_params_}')\n",
    "print(f'Best score      : {grid_search.best_score_:.3f}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DERIVE MODEL FROM TRAINING DATA USING BEST HYPERPARAMETER VALUES (TRAIN MODEL/FIT MODEL)\n",
    "\n",
    "model.set_params(**grid_search.best_params_)\n",
    "# List all selected hyperparameters\n",
    "print(model.get_params(deep=True))\n",
    "\n",
    "model.fit(X_tr,y_tr)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DISPLAY MODEL (MODEL SPECIFIC)\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# VALIDATE MODEL USING TEST DATA\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict target feature for the test data\n",
    "y_tst_pred = pd.Series(model.predict(X_tst), name='y_tst_pred')\n",
    "\n",
    "# Calculate the difference between predicted and real values for the test data\n",
    "err = pd.Series(y_tst_pred.reset_index(drop=True)!=y_tst.reset_index(drop=True), name='err').astype(int)\n",
    "display(pd.concat([y_tst_pred.reset_index(drop=True), y_tst_pred.reset_index(drop=True), err], axis=1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confusion matrix\n",
    "# Display as text (console output)\n",
    "class_labels = sorted(list(pd.concat([y_tst,y_tst_pred], axis=0).unique()))\n",
    "# Alternative : model.classes_\n",
    "cm = confusion_matrix(y_true = y_tst, y_pred = y_tst_pred) \n",
    "print('Predicted label')\n",
    "print(class_labels)\n",
    "print(cm)\n",
    "# Display as heatmap (nicer output in Jupyter)\n",
    "disp = sns.heatmap(cm, square=True, annot=True, cbar=True, cmap='Greys', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "disp.xaxis.tick_top()                # Put x-axis tickers on top\n",
    "disp.xaxis.set_label_position('top') # Put x-axis label on top"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Metrics\n",
    "acc = accuracy_score(y_true=y_tst, y_pred=y_tst_pred)\n",
    "prec = precision_score(y_true=y_tst, y_pred=y_tst_pred, average='weighted')\n",
    "rec = recall_score(y_true=y_tst, y_pred=y_tst_pred, average='weighted')\n",
    "f1 = f1_score(y_true=y_tst, y_pred=y_tst_pred, average='weighted')\n",
    "# Mind this is a multiclass classification problem, so precision, recall and F1 \n",
    "# are calculated by class and averaged.\n",
    "print(f'ACC : {acc:.3f} - PREC : {prec:.3f} - REC : {rec:.3f} - F1 : {f1:.3f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The easiest way to get results by class is to use precision_recall_fscore_support\n",
    "class_labels = sorted(list(pd.concat([y_tst,y_tst_pred], axis=0).unique()))\n",
    "# Alternative : model.classes_\n",
    "# Display precision/recall/fscore/support table as text (consule output)\n",
    "print(class_labels)\n",
    "display(precision_recall_fscore_support(y_true=y_tst, y_pred=y_tst_pred))\n",
    "# Display precision/recall/fscore/support as pandas dataframe (nicer outputin Jupyter)\n",
    "display(pd.DataFrame(precision_recall_fscore_support(y_true=y_tst, y_pred=y_tst_pred), index=['prec','rec','fscore','sup'], columns=class_labels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Or use classification_report\n",
    "print(classification_report(y_true=y_tst, y_pred=y_tst_pred, target_names=class_labels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. PREDICT PENGUIN SPECIES WITH HYPERPARAMETER TUNING USING CROSS-VALIDATION (MANUALLY)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If everything went well, you used specific scikit-learn features for the cross validation and grid search (GridSearchCV) that do all the work (as seen in the lecture). \n",
    "\n",
    "In this exercise, we want you to program the procedure for the hyperparameter tuning with cross-validation yourself. So program the steps of hyperparameter tuning and cross-validation yourself, without using the cross-validation and grid search functions of scikit-learn (so do not use functions like GridSearchCV). \n",
    "\n",
    "Use the same data (target variable and predictors) as in the previous exercise. Find the best model using 3-fold cross validation. To make it simpler, limit the hyperparameters to be checked to split criterion equal to 'entropy' and maximum tree depth equal to 3,5,8 and 10.\n",
    "\n",
    "The only scikit-learn functions you can use are train_test_split, the functions to derive, plot and apply a decision tree (DecisionTreeClassifier and it's methods - fit, predict - plot_tree) and the functions for the calculation of validation metrics (confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, classification_report).\n",
    "\n",
    "So be sure to understand the procedure for hyperparameter tuning with cross-validation (how is the data split, which iterations are needed, how are decisions on the best model taken, ...) and develop a Python program accordingly."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# We do not publish a solution here because it is essential that you develop this yourself instead of just looking at the solution. You can check if your solutions is ok by comparing results with the solutions of the previous exercise.",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
